# -*- coding: utf-8 -*-
# UTF-8 encoding when using korean
import sys
# 인풋값 빠르게 받기 위해
input = sys.stdin.readline

stack_in = []
stack_out = []

while True:
	user_input = input()
	# enq일 때
	if user_input[0:2] == 'en':
		# enq와 숫자 부분 나누기
		comd, num = user_input.split()
		# stack_in에 push
		stack_in.append(num)
	# deq일 때
	elif user_input[0:2] == 'de':
		# stack_out부분이 없을 때만 stack_in에 있는 숫자 채우기 작업 => 평균적으로 O(1)의 작업임
		if not stack_out:
			while stack_in:
				stack_out.append(stack_in.pop())
		# stack_out에서 가장 마지막에 있는 숫자 == Queue에서 가장 첫번째로 들어간 숫자
		if stack_out:
			val = stack_out.pop()
			print(val)
		# 없으면 EMPTY
		else:
			print('EMPTY')
	# exit일 때
	else:
		break

# chat GPT와의 내용

# Q. deque가 평균적으로 상수 시간에 가까운 성능을 보임을 증명할 수 있어?

# A. 네, 두 개의 스택을 사용한 큐 구현에서 평균적으로 상수 시간에 가까운 성능을 보이는 것을 증명할 수 있습니다. 이를 분석하기 위해 amortized analysis라는 기법을 사용하겠습니다.

# 분석을 위해 먼저 각각의 enqueue와 dequeue 작업에 대한 비용을 살펴봅시다.

# enqueue 작업의 비용: 원소를 in_stack에 추가하는 비용은 O(1)입니다.
# dequeue 작업의 비용: out_stack이 비어 있지 않은 경우, 원소를 꺼내는 비용은 O(1)입니다. 하지만 out_stack이 비어 있는 경우, in_stack의 모든 원소를 out_stack으로 옮겨야 하므로 최악의 경우 O(n)의 비용이 발생합니다.
# 여기서 중요한 점은, dequeue 작업에서 최악의 경우 발생하는 O(n)의 비용이 연속해서 발생하지 않는다는 것입니다. dequeue 작업에서 O(n)의 비용이 발생하려면 out_stack이 비어 있어야 합니다. 이는 in_stack의 원소가 모두 out_stack으로 옮겨진 상태로, 이후 dequeue 작업은 O(1)의 비용으로 이루어집니다.

# 여러 enqueue와 dequeue 작업이 연속해서 수행된다고 가정해봅시다. 이때 각각의 원소는 한 번씩만 in_stack에서 out_stack으로 옮겨지게 됩니다. 이 과정에서 원소마다 O(1)의 추가 비용이 발생하므로, 총 m개의 연산(원소의 수보다 많은 경우 포함)에 대한 시간 복잡도는 O(m)이 됩니다.

# 이제 m개의 연산에 대한 평균 시간 복잡도를 계산하면, O(m) / m = O(1)이 됩니다. 따라서 두 개의 스택을 사용한 큐 구현에서 평균적으로 상수 시간에 가까운 성능을 보인다는 것을 증명할 수 있습니다.


# Q.왜 O(m)/m = O(1) 야?

# A. m개의 연산에 대한 총 시간 복잡도는 O(m)입니다. 여기서 한 번의 연산에 대한 평균 시간 복잡도를 구하기 위해 총 시간 복잡도를 연산 횟수인 m으로 나누는 것이 아니라, 총 시간 복잡도가 m개의 연산에 대해 선형적으로 증가함을 의미합니다.

# O(m)이라는 표현은 상수 시간에 m을 곱한 것이기 때문에, 이를 m개의 연산으로 나누면 상수 시간 복잡도가 남게 됩니다. 이때, O(m) / m을 수학적으로 정확한 표현으로 바꾸면 O(1)이 됩니다.

# 따라서, 두 개의 스택을 사용한 큐 구현에서 한 번의 연산에 대한 평균 시간 복잡도가 O(1)이라는 것은, m개의 연산에 대한 총 시간 복잡도가 선형적으로 증가하며 각 연산이 상수 시간에 가까운 성능을 보인다는 것을 의미합니다.


# Q. amortized analysis에 대해 더 알려줄래?

# A. Amortized analysis는 알고리즘의 시간 복잡도를 분석하는 기법 중 하나입니다. 이 방법은 여러 연산을 수행할 때, 각 연산에 대한 평균 시간 복잡도를 구하는 데 사용됩니다. Amortized analysis는 알고리즘이 연산을 수행하는 전체 과정에서 발생하는 시간 복잡도를 살펴보고, 개별 연산이 전체 과정에서 어떤 평균적인 시간 복잡도를 가지는지 분석하는 데 초점을 맞춥니다.

# Amortized analysis는 일반적으로 세 가지 방법으로 수행할 수 있습니다: aggregate analysis, accounting method, potential method.

# Aggregate Analysis (총체적 분석):
# 여러 번의 연산을 수행하는 데 걸리는 전체 시간 복잡도를 구한 다음, 전체 연산 횟수로 나눠 평균 시간 복잡도를 계산하는 방법입니다. 전체 연산에 걸린 시간을 모두 합산하고, 연산 횟수로 나눔으로써 각 연산에 대한 평균 시간 복잡도를 구합니다.

# Accounting Method (회계 방법):
# 이 방법에서는 각 연산에 가상의 "비용(토큰)"을 할당합니다. 연산의 실제 비용과 가상의 비용 사이의 차이를 이용하여, 미래의 연산에 대한 비용을 미리 지불하는 것으로 볼 수 있습니다. 즉, 비용이 낮은 연산이 발생했을 때 미리 비용을 저장해두고, 비용이 높은 연산이 발생했을 때 이를 상쇄하는 방식으로 평균 시간 복잡도를 분석합니다.

# Potential Method (잠재 에너지 방법):
# 시스템의 "잠재 에너지"라는 개념을 도입하여, 시간이 지남에 따라 시스템 상태의 변화를 측정하는 방법입니다. 잠재 에너지는 특정 시점에서 미래에 발생할 연산에 대한 시간 복잡도를 예측하는 데 사용됩니다. 각 연산에 대한 잠재 에너지의 변화를 계산하고, 이를 이용해 평균 시간 복잡도를 분석합니다.

# Amortized analysis는 알고리즘의 전체 작동 과정에서 발생하는 시간 복잡도를 더 정확하게 이해할 수 있게 도와주며, 개별 연산에 대한 최악의 경우보다는 평균적인 경우를 고려

# Amortized analysis는 개별 연산에 대한 최악의 경우보다는 평균적인 경우를 고려합니다. 즉, 알고리즘의 전체 작동 과정에서 발생하는 시간 복잡도를 더 정확하게 이해할 수 있게 도와주며, 알고리즘이 여러 번의 연산을 수행할 때 각 연산에 대한 평균 시간 복잡도를 계산하는 데 초점을 맞춥니다.

# Amortized analysis는 일시적으로 비용이 높은 연산이 발생하더라도 전체 연산에 대한 평균 시간 복잡도가 일정 수준 이하로 유지되는 경우에 유용합니다. 이는 알고리즘 성능을 평가하는 데 있어 전반적인 관점에서 더 현실적인 결과를 제공하며, 단순히 최악의 경우를 고려하는 것보다 개발자가 실제로 예상하는 시나리오에 대한 정보를 제공할 수 있습니다.

# 예를 들어, 동적 배열(dynamic array)이나 두 개의 스택을 사용한 큐 구현 등의 자료 구조에서 Amortized analysis를 사용하여 평균 시간 복잡도를 분석할 수 있습니다. 이러한 자료 구조에서 일부 연산은 개별적으로는 최악의 경우 시간 복잡도를 가지지만, 전체 연산에 대한 평균 시간 복잡도는 상수 시간에 가까운 성능을 보이는 것을 확인할 수 있습니다.

# Amortized analysis를 통해 알고리즘의 전반적인 성능을 이해하고 최적화할 수 있으며, 개별 연산에 대한 최악의 경우를 초점을 맞춘 전통적인 시간 복잡도 분석 방법과는 차별화되는 결과를 제공합니다.





